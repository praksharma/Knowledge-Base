{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zarr\n",
    "\n",
    "Zarr is open standard, for storing large multidimensional arrays. It is designed cloud ready and random access by dividing the data into chunks. Influenced by HDF5, it can be contain metadata and grouped into named hierarchies, annotated with key value metadata alongside the array. \n",
    "\n",
    "* Has multiple compression options and levels built-in \n",
    "\n",
    "* Supports multiple backend data stores (zip, S3, etc.) \n",
    "\n",
    "* Can read and write data in parallel* in n-dimensional compressed chunks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why use Zarr? \n",
    "\n",
    "csv, txt doesn’t store array with more than 3-dimensional arrays. .npy does but can't be scaled to larger-than-memory datasets or other situations in which you want to read and/or write in parallel. \n",
    "\n",
    "## Save NumPy Arrays with Zarr \n",
    "\n",
    "Instead save the numpy arrays with zarr.\n",
    "\n",
    "A very good tutorial: [link](https://freedium.cfd/https:/towardsdatascience.com/why-you-should-save-numpy-arrays-with-zarr-dabff4ae6c0c)\n",
    "\n",
    "## Basic Zarr Workflow\n",
    "\n",
    "### Create a Zarr Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.16792828 0.05855492 0.61850888 0.00334115 0.55858836 0.21650163\n",
      "  0.53774298 0.42341329 0.43683333 0.8620628 ]\n",
      " [0.77786639 0.28022484 0.20837323 0.7247819  0.49771604 0.92462718\n",
      "  0.51060836 0.04236613 0.98047625 0.00410626]\n",
      " [0.38210065 0.36627372 0.00582958 0.72082145 0.24324471 0.40437936\n",
      "  0.13279096 0.00191599 0.4308012  0.94889893]\n",
      " [0.31733476 0.0967293  0.49516206 0.90658001 0.99522668 0.83354\n",
      "  0.87027598 0.11772291 0.65141924 0.15564434]\n",
      " [0.98229912 0.62499048 0.17393857 0.30351276 0.47716583 0.14302452\n",
      "  0.39584313 0.17151204 0.71980751 0.85271517]\n",
      " [0.03644305 0.33025467 0.05553023 0.13553851 0.89252233 0.94528132\n",
      "  0.3219762  0.86822442 0.95530793 0.55626303]\n",
      " [0.24725786 0.55204327 0.80377698 0.06480157 0.90251993 0.92491466\n",
      "  0.37617816 0.4783279  0.88646059 0.35445961]\n",
      " [0.15765295 0.66788802 0.0081186  0.33973027 0.75316576 0.72855571\n",
      "  0.12683921 0.17154689 0.21010142 0.40546485]\n",
      " [0.14055949 0.31744168 0.54813014 0.46988983 0.07017627 0.83640945\n",
      "  0.82357796 0.09766152 0.34136162 0.35717373]\n",
      " [0.03706085 0.4210289  0.42998954 0.98348018 0.05693666 0.51772671\n",
      "  0.05859623 0.69127757 0.61628705 0.53710781]]\n"
     ]
    }
   ],
   "source": [
    "import zarr\n",
    "import numpy as np\n",
    "\n",
    "# Create a Zarr array\n",
    "# Data is stored in 100x100 chunks, optimizing I/O performance.\n",
    "z = zarr.create(shape = (1000, 1000),\n",
    "                chunks = (100,100),\n",
    "                dtype='f8')\n",
    "\n",
    "# Write data to the array\n",
    "z[0: 500, 0:500] = np.random.rand(500, 500)\n",
    "\n",
    "print(z[0:10, 0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store Zarr Data on Disk\n",
    "####  A quick way: [link](https://zarr.readthedocs.io/en/v2.7.1/api/convenience.html#zarr.convenience.save) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "zarr.save('data/data_1.zarr', z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A more efficient way: [link](https://zarr.readthedocs.io/en/v2.7.1/tutorial.html#persistent-arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store zarr array to disk by opening a new file in write mode \n",
    "z_data = zarr.open('data/data_2.zarr', mode='w', shape=(1000, 1000), chunks=(100, 100), dtype='f8')\n",
    "\n",
    "z_data[0:500, 0:500] = np.random.random((500, 500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing both methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type               : zarr.core.Array\n",
      "Data type          : float64\n",
      "Shape              : (1000, 1000)\n",
      "Chunk shape        : (100, 100)\n",
      "Order              : C\n",
      "Read-only          : True\n",
      "Compressor         : Blosc(cname='lz4', clevel=5, shuffle=SHUFFLE, blocksize=0)\n",
      "Store type         : zarr.storage.DirectoryStore\n",
      "No. bytes          : 8000000 (7.6M)\n",
      "No. bytes stored   : 1786823 (1.7M)\n",
      "Storage ratio      : 4.5\n",
      "Chunks initialized : 100/100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Open the saved array\n",
    "z_disk = zarr.open('data/data_1.zarr', mode='r')\n",
    "print(z_disk.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type               : zarr.core.Array\n",
      "Data type          : float64\n",
      "Shape              : (1000, 1000)\n",
      "Chunk shape        : (100, 100)\n",
      "Order              : C\n",
      "Read-only          : True\n",
      "Compressor         : Blosc(cname='lz4', clevel=5, shuffle=SHUFFLE, blocksize=0)\n",
      "Store type         : zarr.storage.DirectoryStore\n",
      "No. bytes          : 8000000 (7.6M)\n",
      "No. bytes stored   : 1752949 (1.7M)\n",
      "Storage ratio      : 4.6\n",
      "Chunks initialized : 25/100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Open the saved array\n",
    "z_disk = zarr.open('data/data_2.zarr', mode='r')\n",
    "print(z_disk.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chunks initialised is 25/100 in persistence mode and 100/100 in convenience mode. So, better use the persistence mode?\n",
    "\n",
    "### Zarr Groups\n",
    "Zarr supports hierarchical data storage (like HDF5), where datasets can be grouped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a group\n",
    "group = zarr.open_group('data/group_data.zarr', mode='w')\n",
    "\n",
    "# Add datasets to the group\n",
    "group.create_dataset('dataset1', shape = z.shape, dtype='f8')\n",
    "group.create_dataset('dataset2', shape = z.shape, dtype='f8')\n",
    "\n",
    "# Access the datasets and save data\n",
    "group['dataset1'][:] = z\n",
    "group['dataset2'][:] = z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zarr with MinIO\n",
    "We can use `s3fs.S3Map` to map Zarr directly to S3 storage. We need to store the data in a zarr group. In the following there is only onw dataset, but we can have multiple datasets in the same group.\n",
    "\n",
    "https://zarr.readthedocs.io/en/stable/tutorial.html#distributed-cloud-storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "\n",
    "fs = s3fs.S3FileSystem(\n",
    "    key = 'minioadmin',\n",
    "    secret = 'minioadmin',\n",
    "    client_kwargs = {'endpoint_url': 'http://localhost:9000'}\n",
    ")\n",
    "\n",
    "# Define the S3 path for zarr to store the data\n",
    "# Use s3fs as the Zarr store directly\n",
    "store = s3fs.S3Map(root='my-bucket-2/data/zarr_data', s3=fs, check=False)\n",
    "\n",
    "# Create a Zarr group\n",
    "root = zarr.group(store=store)\n",
    "\n",
    "# Create a Zarr dataset within the group\n",
    "dataset_3 = root.create_dataset('example_array', shape= z.shape, chunks=(100, 100), dtype='f8')\n",
    "\n",
    "dataset_3[:] = z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my-bucket-2/data', 'my-bucket-2/images']\n",
      "['my-bucket-2/data/data.csv', 'my-bucket-2/data/zarr_data']\n"
     ]
    }
   ],
   "source": [
    "print(fs.ls('my-bucket-2/'))\n",
    "print(fs.ls('s3://my-bucket-2/data/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tree of the S3 database will look like this.\n",
    "```sh\n",
    "╭─\n",
    "╰─ tree -L 4\n",
    ".\n",
    "├── mc\n",
    "├── minio\n",
    "├── my-bucket\n",
    "└── my-bucket-2\n",
    "    ├── data\n",
    "    │   ├── data.csv\n",
    "    │   │   └── xl.meta\n",
    "    │   └── zarr_data\n",
    "    │       └── example_array\n",
    "    └── images\n",
    "        └── minui_web_ui.png\n",
    "            └── xl.meta\n",
    "\n",
    "8 directories, 4 files\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A nice tutorial to learn more about zarr: [link](https://zarr.readthedocs.io/en/v2.7.1/tutorial.html)\n",
    "\n",
    "# Xarray\n",
    "\n",
    "Zarr does not inherently handle labels or metadata beyond basic array attributes. Thus, Zarr is often used with xarray for labeled multi-dimensional large datasets.\n",
    "\n",
    "## Save xarray Dataset to Zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.backends.zarr.ZarrStore at 0x77821091a8c0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xarray as xr\n",
    "\n",
    "# create a xarray dataset\n",
    "data = xr.Dataset({\n",
    "    \"temperature\": ((\"x\", \"y\"), np.random.rand(100, 100)),\n",
    "    \"pressure\" : ((\"x\", \"y\"), np.random.rand(100, 100)),\n",
    "},\n",
    "    coords = {\n",
    "        \"x\": np.arange(100),\n",
    "        \"y\": np.arange(100),\n",
    "    }\n",
    ")\n",
    "\n",
    "# Save to zarr\n",
    "data.to_zarr('data/xarray_data.zarr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Zarr Dataset into xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 162kB\n",
      "Dimensions:      (x: 100, y: 100)\n",
      "Coordinates:\n",
      "  * x            (x) int64 800B 0 1 2 3 4 5 6 7 8 ... 91 92 93 94 95 96 97 98 99\n",
      "  * y            (y) int64 800B 0 1 2 3 4 5 6 7 8 ... 91 92 93 94 95 96 97 98 99\n",
      "Data variables:\n",
      "    pressure     (x, y) float64 80kB dask.array<chunksize=(100, 100), meta=np.ndarray>\n",
      "    temperature  (x, y) float64 80kB dask.array<chunksize=(100, 100), meta=np.ndarray>\n"
     ]
    }
   ],
   "source": [
    "ds = xr.open_zarr('data/xarray_data.zarr')\n",
    "print(ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
